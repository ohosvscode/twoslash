import type { GeneratedEtsLibFile } from "../../types/generated";

export const FILE: GeneratedEtsLibFile = {
  path: 'ets/api/@ohos.ai.mindSporeLite.d.ts',
  content: "/*\n * Copyright (c) 2023 Huawei Device Co., Ltd.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * @file\n * @kit MindSporeLiteKit\n */\nimport { Callback } from './@ohos.base';\n/**\n * @namespace mindSporeLite\n * @syscap SystemCapability.AI.MindSporeLite\n * @stagemodelonly\n * @since 10\n */\ndeclare namespace mindSporeLite {\n    /**\n     * Create a Model instance from file path\n     * @param { string } model - model indicates model path to be loaded\n     * @param { Context } context - context indicates model context information\n     * @returns { Promise<Model> } the promise returned by the function.\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    function loadModelFromFile(model: string, context?: Context): Promise<Model>;\n    /**\n     * Create a Model instance from file path.\n     * @param { string } model - model indicates model path to be loaded\n     * @param { Callback<Model> } callback - the callback of model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    function loadModelFromFile(model: string, callback: Callback<Model>): void;\n    /**\n     * Create a Model instance from file path.\n     * @param { string } model - model indicates model path to be loaded\n     * @param { Context } context - context indicates model context information\n     * @param { Callback<Model> } callback - the callback of model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    function loadModelFromFile(model: string, context: Context, callback: Callback<Model>): void;\n    /**\n     * Create a Model instance from buffer\n     * @param { ArrayBuffer } model - model indicates model buffer to be loaded\n     * @param { Context } [context] - context indicates model context information\n     * @returns { Promise<Model> } the promise returned by the function.\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    function loadModelFromBuffer(model: ArrayBuffer, context?: Context): Promise<Model>;\n    /**\n     * Create a Model instance from buffer\n     * @param { ArrayBuffer } model - model indicates model buffer to be loaded\n     * @param { Callback<Model> } callback - the callback of model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    function loadModelFromBuffer(model: ArrayBuffer, callback: Callback<Model>): void;\n    /**\n     * Create a Model instance from buffer\n     * @param { ArrayBuffer } model - model indicates model buffer to be loaded\n     * @param { Context } context - context indicates model context information\n     * @param { Callback<Model> } callback - the callback of model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    function loadModelFromBuffer(model: ArrayBuffer, context: Context, callback: Callback<Model>): void;\n    /**\n     * Creates a Model instance file description\n     * @param { number } model - model indicates model file description to be loaded\n     * @param { Context } [context] - context indicates model context information\n     * @returns { Promise<Model> } the promise returned by the function.\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    function loadModelFromFd(model: number, context?: Context): Promise<Model>;\n    /**\n     * Create a Model instance from file description\n     * @param { number } model - model indicates model file description to be loaded\n     * @param { Callback<Model> } callback - the callback of model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    function loadModelFromFd(model: number, callback: Callback<Model>): void;\n    /**\n     * Create a Model instance from file description\n     * @param { number } model - model indicates model file description to be loaded\n     * @param { Context } context - context indicates model context information\n     * @param { Callback<Model> } callback - the callback of model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    function loadModelFromFd(model: number, context: Context, callback: Callback<Model>): void;\n    /**\n     * Load train model from file\n     * @param { string } model - model file path\n     * @param { TrainCfg } [trainCfg] - model train configuration\n     * @param { Context } [context] - model build context\n     * @returns { Promise<Model> } the promise of the built model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    function loadTrainModelFromFile(model: string, trainCfg?: TrainCfg, context?: Context): Promise<Model>;\n    /**\n     * Load train model from buffer\n     * @param { ArrayBuffer } model - model buffer\n     * @param { TrainCfg } [trainCfg] - model train configuration\n     * @param { Context } [context] - model build context\n     * @returns { Promise<Model> } the promise of the built model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    function loadTrainModelFromBuffer(model: ArrayBuffer, trainCfg?: TrainCfg, context?: Context): Promise<Model>;\n    /**\n     * Load train model from file description\n     * @param { number } model - model file description\n     * @param { TrainCfg } [trainCfg] - model train configuration\n     * @param { Context } [context] - model build context\n     * @returns { Promise<Model> } the promise of the built model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    function loadTrainModelFromFd(model: number, trainCfg?: TrainCfg, context?: Context): Promise<Model>;\n    /**\n     * Provides manages model function. Including get inputs, predict ,resize.\n     * @typedef Model\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    interface Model {\n        /**\n         * The learning rate of the training model\n         * @type {?number}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        learningRate?: number;\n        /**\n         * The running mode of the model\n         * @type {?boolean}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        trainMode?: boolean;\n        /**\n         * Get model input tensors.\n         * @returns { MSTensor[] } the MSTensor array of the inputs.\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        getInputs(): MSTensor[];\n        /**\n         * Infer model\n         * @param { MSTensor[] } inputs - indicates the MSTensor array of the inputs.\n         * @param { Callback<MSTensor[]> }  callback - the callback of MSTensor array.\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        predict(inputs: MSTensor[], callback: Callback<MSTensor[]>): void;\n        /**\n         * Infer model\n         * @param { MSTensor[] } inputs - indicates the MSTensor array of the inputs.\n         * @returns { Promise<MSTensor[]> } the promise returned by the function.\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        predict(inputs: MSTensor[]): Promise<MSTensor[]>;\n        /**\n         * resize model input\n         * @param { MSTensor[] } inputs - indicates the MSTensor array of the inputs.\n         * @param { Array<Array<number>> } dims - indicates the target new shape array\n         * @returns { boolean } the boolean result if the resize operation is successful\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        resize(inputs: MSTensor[], dims: Array<Array<number>>): boolean;\n        /**\n         * Train model by step\n         * @param { MSTensor[] } inputs - indicates the MSTensor array of the inputs.\n         * @returns { boolean } the boolean result if the runStep operation is successful\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        runStep(inputs: MSTensor[]): boolean;\n        /**\n         * Obtain all weights of the model\n         * @returns { MSTensor[] } the weight tensors of the model\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        getWeights(): MSTensor[];\n        /**\n         * Update weights of the model\n         * @param { MSTensor[] } weights - indicates the MSTensor array of the inputs\n         * @returns { boolean } the boolean result if updating weights operation is successful\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        updateWeights(weights: MSTensor[]): boolean;\n        /**\n         * Setup training with virtual batches\n         * @param { number } virtualBatchMultiplier - virtual batch multiplier, use any number < 1 to disable\n         * @param { number } lr - learning rate to use for virtual batch, -1 for internal configuration\n         * @param { number } momentum - batch norm momentum to use for virtual batch, -1 for internal configuration\n         * @returns { boolean } the boolean result if the operation is successful\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        setupVirtualBatch(virtualBatchMultiplier: number, lr: number, momentum: number): boolean;\n        /**\n         * Export train model to file\n         * @param { string } modelFile - model file path.\n         * @param { QuantizationType } [quantizationType] - the quantization type, default NO_QUANT.\n         * @param { boolean } [exportInferenceOnly] - whether to export a inference only model, default true.\n         * @param { string[] } [outputTensorName] - the set of name of output tensor the exported inference model,\n         * @returns { boolean } - the boolean result if the operation is successful\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        exportModel(modelFile: string, quantizationType?: QuantizationType, exportInferenceOnly?: boolean, outputTensorName?: string[]): boolean;\n        /**\n         * Export model's weights, which can be used in micro only. Only valid for Lite Train\n         * @param { string } weightFile - weight file path\n         * @param { boolean } [isInference] - whether to export weights from inference model, only support this is `true` for now, default true\n         * @param { boolean } [enableFp16] - float-weight is whether to be saved in float16 format, default false\n         * @param { string[] } [changeableWeightsName] - changeable weights name\n         * @returns { boolean } the boolean result if the operation is successful\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        exportWeightsCollaborateWithMicro(weightFile: string, isInference?: boolean, enableFp16?: boolean, changeableWeightsName?: string[]): boolean;\n    }\n    /**\n     * Enum for quantization type\n     * @enum {number}\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    export enum QuantizationType {\n        /**\n         * No quantization.\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        NO_QUANT = 0,\n        /**\n         * Weight quantization.\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        WEIGHT_QUANT = 1,\n        /**\n         * Full quantization.\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        FULL_QUANT = 2\n    }\n    /**\n     * Enum for optimization level\n     * @enum {number}\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    export enum OptimizationLevel {\n        /**\n         * Do not change\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        O0 = 0,\n        /**\n         * Cast network to float16, keep batch norm and loss in float32\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        O2 = 2,\n        /**\n         * Cast network to float16, including batch norm\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        O3 = 3,\n        /**\n         * Choose optimization based on device\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        AUTO = 4\n    }\n    /**\n     * Provides the train configuration\n     * @typedef TrainCfg\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    interface TrainCfg {\n        /**\n         * Array of loss name\n         * @type {?string[]}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        lossName?: string[];\n        /**\n         * Train optimization level\n         * @type {?OptimizationLevel}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        optimizationLevel?: OptimizationLevel;\n    }\n    /**\n     * Provides the device configurations\n     * @typedef Context\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    interface Context {\n        /**\n         * The target device\n         * @type {?string[]}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        target?: string[];\n        /**\n         * The cpu device information\n         * @type {?CpuDevice}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        cpu?: CpuDevice;\n        /**\n         * The NNRT device information\n         * @type {?NNRTDevice}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        nnrt?: NNRTDevice;\n    }\n    /**\n     * Provides the CPU device info\n     * @typedef CpuDevice\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    interface CpuDevice {\n        /**\n         * The thread num\n         * @type {?number}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        threadNum?: number;\n        /**\n         * The thread affinity mode\n         * @type {?ThreadAffinityMode}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        threadAffinityMode?: ThreadAffinityMode;\n        /**\n         * The thread affinity core list\n         * @type {?number[]}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        threadAffinityCoreList?: number[];\n        /**\n         * The precision mode\n         * @type {?string}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        precisionMode?: string;\n    }\n    /**\n     * Enum for performance mode\n     * @enum {number}\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    export enum PerformanceMode {\n        /**\n         * No performance mode preference\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        PERFORMANCE_NONE = 0,\n        /**\n         * Low power consumption mode\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        PERFORMANCE_LOW = 1,\n        /**\n         * Medium performance mode\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        PERFORMANCE_MEDIUM = 2,\n        /**\n         * High performance mode\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        PERFORMANCE_HIGH = 3,\n        /**\n         * Ultimate performance mode\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        PERFORMANCE_EXTREME = 4\n    }\n    /**\n     * Enum for scheduling priority\n     * @enum {number}\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    export enum Priority {\n        /**\n         * No priority preference\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        PRIORITY_NONE = 0,\n        /**\n         * Low priority\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        PRIORITY_LOW = 1,\n        /**\n         * Medium priority\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        PRIORITY_MEDIUM = 2,\n        /**\n         * High priority\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        PRIORITY_HIGH = 3\n    }\n    /**\n     * Provides the extension information of nnrt device\n     * @typedef Extension\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    interface Extension {\n        /**\n         * Extension name\n         * @type {string}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        name: string;\n        /**\n         * Extension array buffer\n         * @type {ArrayBuffer}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        value: ArrayBuffer;\n    }\n    /**\n     * Enum for nnrt device type\n     * @enum {number}\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    export enum NNRTDeviceType {\n        /**\n         * Devices that are not CPU, GPU, or dedicated accelerator\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        NNRTDEVICE_OTHERS = 0,\n        /**\n         * CPU device\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        NNRTDEVICE_CPU = 1,\n        /**\n         * GPU device\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        NNRTDEVICE_GPU = 2,\n        /**\n         * Dedicated hardware accelerator\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        NNRTDEVICE_ACCELERATOR = 3\n    }\n    /**\n     * Provides the nnrt device description\n     * @typedef NNRTDeviceDescription\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    interface NNRTDeviceDescription {\n        /**\n         * Get device id\n         * @returns { bigint } the number of device id\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        deviceID(): bigint;\n        /**\n         * Get device type.\n         * @returns { NNRTDeviceType } the device type\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        deviceType(): NNRTDeviceType;\n        /**\n         * Get device name.\n         * @returns { string } device name\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        deviceName(): string;\n    }\n    /**\n     * Obtain the all device descriptions in NNRT.\n     * @returns { NNRTDeviceDescription[] } the array of NNRTDeviceDescription\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 12\n     */\n    function getAllNNRTDeviceDescriptions(): NNRTDeviceDescription[];\n    /**\n     * Provides the NNRT device info\n     * @typedef NNRTDevice\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    interface NNRTDevice {\n        /**\n         * NNRT device id.\n         * @type {?bigint}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        deviceID?: bigint;\n        /**\n         * NNRT device performance mode.\n         * @type {?PerformanceMode}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        performanceMode?: PerformanceMode;\n        /**\n         * NNRT device priority.\n         * @type {?Priority}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        priority?: Priority;\n        /**\n         * NNRT device extension array.\n         * @type {?Extension[]}\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 12\n         */\n        extensions?: Extension[];\n    }\n    /**\n     * Enum for provides CPU thread affinity mode\n     * @enum {number}\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    export enum ThreadAffinityMode {\n        /**\n         * Thread affinity mode is no bind.\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        NO_AFFINITIES = 0,\n        /**\n         * Thread affinity mode is big cores first\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        BIG_CORES_FIRST = 1,\n        /**\n         * Thread affinity mode is little cores first\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        LITTLE_CORES_FIRST = 2\n    }\n    /**\n     * Provides MSTensor definition\n     * @typedef MSTensor\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    interface MSTensor {\n        /**\n          * The name of the tensor.\n          * @type {string}\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        name: string;\n        /**\n          * The shape of the tensor.\n          * @type {number[]}\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        shape: number[];\n        /**\n          * The number of elements in the tensor.\n          * @type {number}\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        elementNum: number;\n        /**\n          * The data size of the tensor.\n          * @type {number}\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        dataSize: number;\n        /**\n          * The data type of the tensor.\n          * @type {DataType}\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        dtype: DataType;\n        /**\n          * The format of the tensor.\n          * @type {Format}\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        format: Format;\n        /**\n         * Get MSTensor data\n         * @returns { ArrayBuffer } the data of tensor\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        getData(): ArrayBuffer;\n        /**\n         * Set MSTensor data\n         * @param { ArrayBuffer } inputArray - indicates the buffer of tensor\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        setData(inputArray: ArrayBuffer): void;\n    }\n    /**\n     * Enum for provides MSTensor data type\n     * @enum {number}\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    export enum DataType {\n        /**\n         * data type is unknown\n         * @syscap SystemCapability.AI.MindSporeLite\n         * @stagemodelonly\n         * @since 10\n         */\n        TYPE_UNKNOWN = 0,\n        /**\n          * data type is int8\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_INT8 = 32,\n        /**\n          * data type is int16\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_INT16 = 33,\n        /**\n          * data type is int32\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_INT32 = 34,\n        /**\n          * data type is int64\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_INT64 = 35,\n        /**\n          * data type is uint8\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_UINT8 = 37,\n        /**\n          * data type is uint16\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_UINT16 = 38,\n        /**\n          * data type is uint32\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_UINT32 = 39,\n        /**\n          * data type is uint64\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_UINT64 = 40,\n        /**\n          * data type is float16\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_FLOAT16 = 42,\n        /**\n          * data type is float32\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_FLOAT32 = 43,\n        /**\n          * data type is float64\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NUMBER_TYPE_FLOAT64 = 44\n    }\n    /**\n     * Enum for provides MSTensor format\n     * @enum {number}\n     * @syscap SystemCapability.AI.MindSporeLite\n     * @stagemodelonly\n     * @since 10\n     */\n    export enum Format {\n        /**\n          * data format is default\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        DEFAULT_FORMAT = -1,\n        /**\n          * data format is NCHW\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NCHW = 0,\n        /**\n          * data format is NHWC\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NHWC = 1,\n        /**\n          * data format is NHWC4\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        NHWC4 = 2,\n        /**\n          * data format is HWKC\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        HWKC = 3,\n        /**\n          * data format is HWCK\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        HWCK = 4,\n        /**\n          * data format is KCHW\n          * @syscap SystemCapability.AI.MindSporeLite\n          * @stagemodelonly\n          * @since 10\n          */\n        KCHW = 5\n    }\n}\nexport default mindSporeLite;\n",
}
export default FILE;