import type { GeneratedEtsLibFile } from "../../types/generated";

export const FILE: GeneratedEtsLibFile = {
  path: 'ets/api/@ohos.test.PerfTest.d.ts',
  content: "/*\n * Copyright (c) 2025 Huawei Device Co., Ltd.\n * Licensed under the Apache License, Version 2.0 (the \"License\"),\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * @file\n * @kit TestKit\n */\nimport { Callback } from './@ohos.base';\n/**\n * Enumerates the metric type of performance test.\n *\n * @enum { number }\n * @syscap SystemCapability.Test.PerfTest\n * @atomicservice\n * @since 20\n * @test\n */\ndeclare enum PerfMetric {\n    /**\n     * Duration of the single execution, the unit is ms.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    DURATION = 0,\n    /**\n     * Process CPU load during a single execution, the unit is %.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    CPU_LOAD = 1,\n    /**\n     * Process CPU usage during a single execution, the unit is %.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    CPU_USAGE = 2,\n    /**\n     * Memory change before and after a single execution, including the shared library, the unit is KB.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    MEMORY_RSS = 3,\n    /**\n     * Memory change before and after a single execution, excluding shared libraries, the unit is KB.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    MEMORY_PSS = 4,\n    /**\n     * Application start response delay, the unit is ms.\n     * Marks:\n     * 1) Delay calculation is restricted by system dotting reporting. The start time is the time when the click event is reported,\n     * and the end time of the response delay is the time when the system responds to the first frame after the click.\n     * It is different from the end-to-end user-perceived delay.\n     * 2) Application start delay can be collected in the following scenarios: clicking the application icon on the desktop;\n     * clicking the application on the Multi-Task Center; clicking the application icon on the Dock;\n     * clicking the application icon on the application center.\n     * 3) This metric does not support the test of current application.\n     * 4) During the test, only the data of the first startup of the specified application can be collected.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    APP_START_RESPONSE_TIME = 5,\n    /**\n     * Application start completion delay, the unit is ms.\n     * Marks:\n     * 1) Delay calculation is restricted by system dotting reporting. The start time is the time when the click event is reported,\n     * and the end time of the completion delay is the time when the first frame is displayed after the application is started.\n     * It is different from the end-to-end user-perceived delay.\n     * 2) Application start delay can be collected in the following scenarios: clicking the application icon on the desktop;\n     * clicking the application on the Multi-Task Center; clicking the application icon on the Dock;\n     * clicking the application icon on the application center.\n     * 3) This metric does not support the test of current application.\n     * 4) During the test, only the data of the first start of specified application can be collected.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    APP_START_COMPLETE_TIME = 6,\n    /**\n     * Page switching completion delay, the unit is ms.\n     * Marks:\n     * 1) Delay calculation is restricted by system dotting and reporting. The start time is the time when the click event is reported,\n     * and the end time of the completion delay is the time when the first frame is displayed after page is switched.\n     * It is different from the end-to-end user-perceived delay.\n     * 2) Page switching delay can be collected in the page switchover scenario of the Router or Navigation component.\n     * 3) During the test, only the data of the first page switching in specified application can be collected.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    PAGE_SWITCH_COMPLETE_TIME = 7,\n    /**\n     * List sliding frame rate, the unit is fps.\n     * Mark:\n     * 1) List sliding frame rate: refers to the frequency at which the screen can be refreshed when the list is sliding.\n     * Only the sliding frame rate of the List, grid, scroll, and waterflow scroll components of ArKUI subsystems can be collected.\n     * 2) During the test, only the data of the first sliding of the component in specified application can be collected.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    LIST_SWIPE_FPS = 8\n}\n/**\n * Test task execution strategy, which is used to initialize the PerfTest object in {@link PerfTest.create}.\n *\n * @typedef PerfTestStrategy\n * @syscap SystemCapability.Test.PerfTest\n * @atomicservice\n * @since 20\n * @test\n */\ndeclare interface PerfTestStrategy {\n    /**\n     * List of performance metrics to be collected.\n     *\n     * @type { Array<PerfMetric> }\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    metrics: Array<PerfMetric>;\n    /**\n     * Code segment for performance testing.\n     * The input parameter type of actionCode is {@link Callback<boolean>}. As actionCode can be defined as asynchronous function,\n     * developers need to invoke this callback function when the execution of actionCode is complete,\n     * to help PerfTest identify the time when the execution of the actionCode is complete.\n     * For example, the input parameter callback function of actionCode is defined as \"(finish: Callback<boolean>)\".\n     * When actionCode is executed completly, \"finish(true)\" should be invoked, the value true indicates actionCode is successfully executed.\n     * When an exception occurs, \"finish(false)\" should be invoked, the value false indicates actionCode is unsuccessfully executed.\n     *\n     * @type { Callback<Callback<boolean>> }\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    actionCode: Callback<Callback<boolean>>;\n    /**\n     * Reset code segment after each test. It is executed after {@link actionCode}. Data collection is not performed during this execution.\n     * The input parameter type of resetCode is {@link Callback<boolean>}. As resetCode can be defined as asynchronous function,\n     * developers need to invoke this callback function when the execution of resetCode is complete,\n     * to help PerfTest identify the time when the execution of the resetCode is complete.\n     * For example, the input parameter callback function of resetCode is defined as \"(finish: Callback<boolean>)\".\n     * When resetCode is executed completly, \"finish(true)\" should be invoked, the value true indicates resetCode is successfully executed.\n     * When an exception occurs, \"finish(false)\" should be invoked, the value false indicates resetCode is unsuccessfully executed.\n     *\n     * @type { ?Callback<Callback<boolean>> }\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    resetCode?: Callback<Callback<boolean>>;\n    /**\n     * The package name of the application to be tested. The default value is the package name of current application.\n     *\n     * @type { ?string }\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    bundleName?: string;\n    /**\n     * Iterations of the test, default is 5.\n     *\n     * @type { ?number }\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    iterations?: number;\n    /**\n     * Timeout in millisecond for executing a single-time {@link actionCode} or {@link resetCode}, default is 10000.\n     *\n     * @type { ?number }\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    timeout?: number;\n}\n/**\n * Test results of specified performance metric.\n *\n * @typedef PerfMeasureResult\n * @syscap SystemCapability.Test.PerfTest\n * @atomicservice\n * @since 20\n * @test\n */\ndeclare interface PerfMeasureResult {\n    /**\n     * The metric this result belongs to.\n     *\n     * @type { PerfMetric }\n     * @readonly\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    readonly metric: PerfMetric;\n    /**\n     * The round values of the specified metric in the test.\n     *\n     * @type { Array<number> }\n     * @readonly\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    readonly roundValues: Array<number>;\n    /**\n     * The maximum of the specified metric in the test.\n     *\n     * @type { number }\n     * @readonly\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    readonly maximum: number;\n    /**\n     * The minimum of the specified metric in the test.\n     *\n     * @type { number }\n     * @readonly\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    readonly minimum: number;\n    /**\n     * The average of the specified metric in the test.\n     *\n     * @type { number }\n     * @readonly\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    readonly average: number;\n}\n/**\n * The unified facade of PerformanceTest framework, can be used to executing the performance test task.\n *\n * @syscap SystemCapability.Test.PerfTest\n * @atomicservice\n * @since 20\n * @test\n */\ndeclare class PerfTest {\n    /**\n     * Create an {@link PerfTest} object.\n     *\n     * @param { PerfTestStrategy } strategy - test task execution strategy.\n     * @returns { PerfTest } the {@link PerfTest} object.\n     * @throws { BusinessError } 32400001 - Initialization failed.\n     * @throws { BusinessError } 32400002 - Internal error. Possible causes: 1. IPC connection failed. 2. The object does not exist.\n     * @throws { BusinessError } 32400003 - Parameter verification failed.\n     * @throws { BusinessError } 32400007 - The API does not support concurrent calls.\n     * @static\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    static create(strategy: PerfTestStrategy): PerfTest;\n    /**\n     * Start the performance test.\n     *\n     * @returns { Promise<void> }\n     * @throws { BusinessError } 32400002 - Internal error. Possible causes: 1. IPC connection failed. 2. The object does not exist.\n     * @throws { BusinessError } 32400004 - Failed to execute the callback. Possible causes: 1. An exception is thrown in the callback. 2. Callback execution timed out.\n     * @throws { BusinessError } 32400005 - Failed to collect metric data.\n     * @throws { BusinessError } 32400007 - The API does not support concurrent calls.\n     *\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    run(): Promise<void>;\n    /**\n     * Get the test result of a specified performance metric. If no test result exist, -1 is returned for all results.\n     *\n     * @param { PerfMetric } metric - performance metric for which the result will be get.\n     * @returns { PerfMeasureResult } test results of specified performance metric.\n     * @throws { BusinessError } 32400002 - Internal error. Possible causes: 1. IPC connection failed. 2. The object does not exist.\n     * @throws { BusinessError } 32400003 - Parameter verification failed.\n     * @throws { BusinessError } 32400006 - Failed to obtain the measurement result.\n     * @throws { BusinessError } 32400007 - The API does not support concurrent calls.\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    getMeasureResult(metric: PerfMetric): PerfMeasureResult;\n    /**\n     * Destroy the {@link PerfTest} object.\n     * @throws { BusinessError } 32400002 - Internal error. Possible causes: 1. IPC connection failed. 2. The object does not exist.\n     * @throws { BusinessError } 32400007 - The API does not support concurrent calls.\n     * @syscap SystemCapability.Test.PerfTest\n     * @atomicservice\n     * @since 20\n     * @test\n     */\n    destroy(): void;\n}\nexport { PerfMetric, PerfTestStrategy, PerfMeasureResult, PerfTest };\n",
}
export default FILE;